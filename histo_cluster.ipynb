{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/sawankumar94/Key-Frames-Extraction-from-Video\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 118.38357162475586 seconds ---\n",
      "(1944, 5971)\n",
      "5971\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('sample.mp4') \n",
    "\n",
    "arr = np.empty((0, 1944), int)   #initializing 1944 dimensional array to store 'flattened' color histograms\n",
    "D=dict()   #to store the original frame (array)\n",
    "count=0    #counting the number of frames\n",
    "start_time = time.time()\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # Read the video file.\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # If we got frames.\n",
    "    if ret == True:\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  #since cv reads frame in bgr order so rearraning to get frames in rgb order\n",
    "        D[count] = frame_rgb   #storing each frame (array) to D , so that we can identify key frames later \n",
    "        \n",
    "        #dividing a frame into 3*3 i.e 9 blocks\n",
    "        height, width, channels = frame_rgb.shape\n",
    "\n",
    "        if height % 3 == 0:\n",
    "            h_chunk = int(height/3)\n",
    "        else:\n",
    "            h_chunk = int(height/3) + 1\n",
    "\n",
    "        if width % 3 == 0:\n",
    "            w_chunk = int(width/3)\n",
    "        else:\n",
    "            w_chunk = int(width/3) + 1\n",
    "\n",
    "        h=0\n",
    "        w= 0 \n",
    "        feature_vector = []\n",
    "        for a in range(1,4):\n",
    "            h_window = h_chunk*a\n",
    "            for b in range(1,4):\n",
    "                frame = frame_rgb[h : h_window, w : w_chunk*b , :]\n",
    "                hist = cv2.calcHist(frame, [0, 1, 2], None, [6, 6, 6], [0, 256, 0, 256, 0, 256])#finding histograms for each block  \n",
    "                hist1= hist.flatten()  #flatten the hist to one-dimensinal vector \n",
    "                feature_vector += list(hist1)\n",
    "                w = w_chunk*b\n",
    "                \n",
    "            h = h_chunk*a\n",
    "            w= 0\n",
    "\n",
    "                \n",
    "        arr =np.vstack((arr, feature_vector )) #appending each one-dimensinal vector to generate N*M matrix (where N is number of frames\n",
    "          #and M is 1944) \n",
    "        count+=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "final_arr = arr.transpose() #transposing so that i will have all frames in columns i.e M*N dimensional matrix \n",
    "#where M is 1944 and N is number of frames\n",
    "print(final_arr.shape)\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "A = csc_matrix(final_arr, dtype=float)\n",
    "\n",
    "#top 63 singular values from 76082 to 508\n",
    "u, s, vt = svds(A, k = 63)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1944, 63) (63,) (63, 5971)\n"
     ]
    }
   ],
   "source": [
    "print(u.shape, s.shape, vt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[510.65808370464373, 530.2718021662525, 550.3389517980506, 586.8739113376688, 593.5044320291942, 611.4275659348356, 622.8557471156001, 638.8026393451155, 741.3548460642296, 766.0055256527369, 815.4971729541109, 850.9658806756527, 880.1532394751533, 1015.869370286953, 1021.1378895773206, 1080.7847387632935, 1196.359379520524, 1223.635370151697, 1294.9920588264, 1408.590757157346, 1454.0354808127306, 1554.7831836167254, 1587.032426553146, 1642.7982412839021, 1790.0419462749244, 1816.8504850283189, 1881.0759545812498, 1967.4320569341746, 2045.849497852996, 2075.9436134303855, 2196.104382164813, 2295.9151740408947, 2449.777598093603, 2522.8972791758556, 2593.2662962295417, 2704.2294984992627, 2788.5253386180043, 2808.278564050423, 2873.0591765833283, 3105.8015296873823, 3208.5137454811293, 3385.1956498191366, 3633.4703046748664, 3756.533065255681, 3980.1660303787908, 4160.3753072356, 4338.834557277577, 4720.443486098456, 4842.275140089515, 5300.937932714548, 5817.152042870614, 6218.873096960126, 6830.11278158553, 7854.436744719318, 8124.284970922861, 8788.126100343663, 9001.18116269527, 10997.38769801295, 11582.651547222744, 13814.824780052537, 15232.193521675154, 24044.704145234573, 54346.867824861125]\n"
     ]
    }
   ],
   "source": [
    "print(list(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5971, 63)\n"
     ]
    }
   ],
   "source": [
    "v1_t = vt.transpose()\n",
    "\n",
    "projections = v1_t @ np.diag(s) #the column vectors i.e the frame histogram data has been projected onto the orthonormal basis \n",
    "#formed by vectors of the left singular matrix u .The coordinates of the frames in this space are given by v1_t @ np.diag(s)\n",
    "#So we can see that , now we need only 63 dimensions to represent each column/frame \n",
    "print(projections.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dynamic clustering of projected frame histograms to find which all frames are similar i.e make shots\n",
    "f=projections\n",
    "C = dict() #to store frames in respective cluster\n",
    "for i in range(f.shape[0]):\n",
    "    C[i] = np.empty((0,63), int)\n",
    "    \n",
    "#adding first two projected frames in first cluster i.e Initializaton    \n",
    "C[0] = np.vstack((C[0], f[0]))   \n",
    "C[0] = np.vstack((C[0], f[1]))\n",
    "\n",
    "E = dict() #to store centroids of each cluster\n",
    "for i in range(projections.shape[0]):\n",
    "    E[i] = np.empty((0,63), int)\n",
    "    \n",
    "E[0] = np.mean(C[0], axis=0) #finding centroid of C[0] cluster\n",
    "\n",
    "count = 0\n",
    "for i in range(2,f.shape[0]):\n",
    "    similarity = np.dot(f[i], E[count])/( (np.dot(f[i],f[i]) **.5) * (np.dot(E[count], E[count]) ** .5)) #cosine similarity\n",
    "    #this metric is used to quantify how similar is one vector to other. The maximum value is 1 which indicates they are same\n",
    "    #and if the value is 0 which indicates they are orthogonal nothing is common between them.\n",
    "    #Here we want to find similarity between each projected frame and last cluster formed chronologically. \n",
    "     \n",
    "    \n",
    "    if similarity < 0.9: #if the projected frame and last cluster formed  are not similar upto 0.9 cosine value then \n",
    "                         #we assign this data point to newly created cluster and find centroid \n",
    "                         #We checked other thresholds also like 0.85, 0.875, 0.95, 0.98\n",
    "                        #but 0.9 looks okay because as we go below then we get many key-frames for similar event and \n",
    "                        #as we go above we have lesser number of key-frames thus missed some events. So, 0.9 seems optimal.\n",
    "                        \n",
    "        count+=1         \n",
    "        C[count] = np.vstack((C[count], f[i])) \n",
    "        E[count] = np.mean(C[count], axis=0)   \n",
    "    else:  #if they are similar then assign this data point to last cluster formed and update the centroid of the cluster\n",
    "        C[count] = np.vstack((C[count], f[i])) \n",
    "        E[count] = np.mean(C[count], axis=0)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []  #find the number of data points in each cluster formed.\n",
    "\n",
    "#We can assume that sparse clusters indicates \n",
    "#transition between shots so we will ignore these frames which lies in such clusters and wherever the clusters are densely populated indicates they form shots\n",
    "#and we can take the last element of these shots to summarise that particular shot\n",
    "\n",
    "for i in range(f.shape[0]):\n",
    "    b.append(C[i].shape[0])\n",
    "\n",
    "last = b.index(0)  #where we find 0 in b indicates that all required clusters have been formed , so we can delete these from C\n",
    "b1=b[:last ] #The size of each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "res = [idx for idx, val in enumerate(b1) if val >= 25] #so i am assuming any dense cluster with atleast 25 frames is eligible to \n",
    "#make shot.\n",
    "print(len(res)) #so total 25 shots with 46 (71-25) cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GG = C #copying the elements of C to GG, the purpose of  the below code is to label each cluster so later \n",
    "#it would be easier to identify frames in each cluster\n",
    "for i in range(last):\n",
    "    p1= np.repeat(i, b1[i]).reshape(b1[i],1)\n",
    "    GG[i] = np.hstack((GG[i],p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the purpose of the below code is to append each cluster to get multidimensional array of dimension N*64, N is number of frames\n",
    "F=  np.empty((0,64), int) \n",
    "for i in range(last):\n",
    "    F = np.vstack((F,GG[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11', 'v12', 'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19', 'v20', 'v21', 'v22', 'v23', 'v24', 'v25', 'v26', 'v27', 'v28', 'v29', 'v30', 'v31', 'v32', 'v33', 'v34', 'v35', 'v36', 'v37', 'v38', 'v39', 'v40', 'v41', 'v42', 'v43', 'v44', 'v45', 'v46', 'v47', 'v48', 'v49', 'v50', 'v51', 'v52', 'v53', 'v54', 'v55', 'v56', 'v57', 'v58', 'v59', 'v60', 'v61', 'v62', 'v63', 'v64']\n"
     ]
    }
   ],
   "source": [
    "#converting F (multidimensional array)  to dataframe\n",
    "\n",
    "colnames = []\n",
    "for i in range(1, 65):\n",
    "    col_name = \"v\" + str(i)\n",
    "    colnames+= [col_name]\n",
    "print(colnames)\n",
    "\n",
    "df = pd.DataFrame(F, columns= colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['v64']= df['v64'].astype(int)  #converting the cluster level from float type to integer type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =  df[df.v64.isin(res)]   #filter only those frames which are eligible to be a part of shot or filter those frames who are\n",
    "#part of required clusters that have more than 25 frames in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = df1.groupby('v64').tail(1)['v64'] #For each cluster /group take its last element which summarize the shot i.e key-frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new1 = new.index #finding key-frames (frame number so that we can go back get the original picture)\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\J_tarp\\Framesframe_97.png\n",
      "E:\\J_tarp\\Framesframe_298.png\n",
      "E:\\J_tarp\\Framesframe_534.png\n",
      "E:\\J_tarp\\Framesframe_765.png\n",
      "E:\\J_tarp\\Framesframe_1217.png\n",
      "E:\\J_tarp\\Framesframe_1268.png\n",
      "E:\\J_tarp\\Framesframe_1554.png\n",
      "E:\\J_tarp\\Framesframe_1768.png\n",
      "E:\\J_tarp\\Framesframe_1867.png\n",
      "E:\\J_tarp\\Framesframe_1921.png\n",
      "E:\\J_tarp\\Framesframe_2005.png\n",
      "E:\\J_tarp\\Framesframe_2219.png\n",
      "E:\\J_tarp\\Framesframe_2459.png\n",
      "E:\\J_tarp\\Framesframe_2505.png\n",
      "E:\\J_tarp\\Framesframe_2655.png\n",
      "E:\\J_tarp\\Framesframe_2686.png\n",
      "E:\\J_tarp\\Framesframe_2714.png\n",
      "E:\\J_tarp\\Framesframe_2743.png\n",
      "E:\\J_tarp\\Framesframe_2824.png\n",
      "E:\\J_tarp\\Framesframe_2870.png\n",
      "E:\\J_tarp\\Framesframe_2932.png\n",
      "E:\\J_tarp\\Framesframe_2988.png\n",
      "E:\\J_tarp\\Framesframe_3015.png\n",
      "E:\\J_tarp\\Framesframe_3118.png\n",
      "E:\\J_tarp\\Framesframe_3230.png\n",
      "E:\\J_tarp\\Framesframe_3260.png\n",
      "E:\\J_tarp\\Framesframe_3305.png\n",
      "E:\\J_tarp\\Framesframe_3346.png\n",
      "E:\\J_tarp\\Framesframe_3510.png\n",
      "E:\\J_tarp\\Framesframe_3616.png\n",
      "E:\\J_tarp\\Framesframe_3667.png\n",
      "E:\\J_tarp\\Framesframe_3762.png\n",
      "E:\\J_tarp\\Framesframe_3812.png\n",
      "E:\\J_tarp\\Framesframe_3870.png\n",
      "E:\\J_tarp\\Framesframe_3924.png\n",
      "E:\\J_tarp\\Framesframe_4212.png\n",
      "E:\\J_tarp\\Framesframe_4448.png\n",
      "E:\\J_tarp\\Framesframe_4571.png\n",
      "E:\\J_tarp\\Framesframe_4619.png\n",
      "E:\\J_tarp\\Framesframe_4753.png\n",
      "E:\\J_tarp\\Framesframe_5023.png\n",
      "E:\\J_tarp\\Framesframe_5081.png\n",
      "E:\\J_tarp\\Framesframe_5190.png\n",
      "E:\\J_tarp\\Framesframe_5480.png\n",
      "E:\\J_tarp\\Framesframe_5579.png\n",
      "E:\\J_tarp\\Framesframe_5635.png\n",
      "E:\\J_tarp\\Framesframe_5803.png\n",
      "E:\\J_tarp\\Framesframe_5970.png\n"
     ]
    }
   ],
   "source": [
    "dir = \"E:\\J_tarp\\Frames\"\n",
    "\n",
    "#output the frames in png format\n",
    "for c in new1:\n",
    "    frame_rgb1 = cv2.cvtColor(D[c], cv2.COLOR_RGB2BGR) #since cv consider image in BGR order\n",
    "    frame_num_chr = str(c)\n",
    "    file_name = 'frame_'+ frame_num_chr +'.png'\n",
    "    print(dir+file_name)\n",
    "    cv2.imwrite(dir + \"/\" + file_name, frame_rgb1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
